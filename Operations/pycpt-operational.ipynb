{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c986233",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# PyCPT Version 2.2dev\n",
    "\n",
    "This is an example of a PyCPT Version 2 seasonal climate forecasting workflow. This notebook can be adapted to suit your exact needs through modifications of the code. This notebook uses PyCPT v2 utilities to \n",
    "\n",
    "1. download data from the IRI Data Library (through the CPT-DL python library) \n",
    "2. Run bias-correction using the IRI Climate Predictability Tool (through its companion python library, CPT-CORE) \n",
    "3. Plot skills scores and spatial loadings\n",
    "4. Produce a multi-model ensemble forecast by taking the simple average of the bias-corrected members\n",
    "5. Plots skill scores, deterministic forecasts, probabilistic forecasts, and exceedance probabilities for this NextGen MME forecast. \n",
    "\n",
    "PyCPT Version 2 was primarily designed and implemented by Kyle Hall.\n",
    "\n",
    "## Function documentation\n",
    "To get help on a function, e.g. `notebook.setup`, run the following command in a new cell:\n",
    "```\n",
    "notebook.setup?\n",
    "```\n",
    "To see the function's source code, use two question marks instead of one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5adcf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Imports - This cell imports PyCPTv2 libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fb2b87",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import cptdl as dl \n",
    "import cptcore as cc \n",
    "import cptextras as ce\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import xarray as xr \n",
    "\n",
    "import notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040d9b2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Define case directory\n",
    "The directory where inputs, outputs, and figures generated by this notebook will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef6b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_dir = Path.home() / \"Desktop/PyCPT\" / \"WAfricaJAS_startJun\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4d5ef",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Parameters - This cell defines the parameters of your CPT analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ded6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOS = 'CCA' # must be one of 'CCA', 'PCR', or \"None\"\n",
    "predictor_names = [ \"SPEAR.PRCP\", \"CCSM4.PRCP\", \"CanSIPSIC3.PRCP\",\"CFSv2.PRCP\",\"GEOSS2S.PRCP\"]# ['CFSv2.PRCP','SEAS5.PRCP']\n",
    "predictand_name = 'UCSB.PRCP'\n",
    "\n",
    "#predictor_names = ['SPEAR.TMAX','CanSIPSIC3.TMAX']\n",
    "#predictand_name = 'UCSB.TMAX'\n",
    "\n",
    "# use dl.observations.keys() to see all options for predictand \n",
    "# and dl.hindcasts.keys() to see all options for predictors\n",
    "# make sure your first_year & final_year are compatible with \n",
    "# your selections for your predictors and predictands \n",
    "\n",
    "download_args = { \n",
    "   # 'fdate':\n",
    "   #   the initialization date of the model forecasts / hindcasts\n",
    "   #   this field is defined by a python datetime.datetime object\n",
    "   #   for example: dt.datetime(2022, 5, 1) # YYYY, MM, DD as integers\n",
    "   #   The year field is only used for forecasts, otherwise ignored\n",
    "   #   The day field is only used in subseasonal forecasts, otherwise ignored\n",
    "   #   The month field is an integer representing a month - ie, May=5\n",
    "  'fdate':  dt.datetime(2023, 2, 1), #dt.datetime(2022, 6, 1),  \n",
    "    \n",
    "   # 'first_year':\n",
    "   #   the first year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**\n",
    "   #   double check that your model has hindcast data for all years in [first_year, final_year]\n",
    "   #   This field is defined by a python integer representing a year, ie: 1993\n",
    "  'first_year': 1991,  \n",
    "    \n",
    "   # 'final_year':\n",
    "   #   the final year of hindcasts you want. **NOT ALL MODELS HAVE ALL YEARS**\n",
    "   #   double check that your model has hindcast data for all years in [first_year, final_year]\n",
    "   #   This field is defined by a python integer representing a year, ie: 2016\n",
    "  'final_year': 2020,  \n",
    "    \n",
    "   # 'predictor_extent':\n",
    "   #   The geographic bounding box of the climate model data you want to download\n",
    "   #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "   #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "   #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "   #   \"south\" the southernmost boundary. Example: {\"north\": 90, \"south\": 90, \"east\": 0, \"west\": 180}\n",
    "  'predictor_extent': {\n",
    "    'east':  -67, #20,\n",
    "    'west': -78, #-20, \n",
    "    'north': -18, #20,\n",
    "    'south': -57 #0 \n",
    "  }, \n",
    "    \n",
    "   # 'predictand_extent':\n",
    "   #   The geographic bounding box of the observation data you want to download\n",
    "   #   This field is defined by a python dictionary with the keys \"north\", \"south\",\n",
    "   #   \"east\", and \"west\", each of which maps to a python integer representing the \n",
    "   #   edge of a bounding box. i.e., \"north\" will be the northernmost boundary,\n",
    "   #   \"south\" the southernmost boundary. Example: {\"north\": 90, \"south\": 90, \"east\": 0, \"west\": 180}\n",
    "  'predictand_extent': {\n",
    "    'east':  -67, #10, \n",
    "    'west': -78, #-18,  \n",
    "    'north': -18, #18,  \n",
    "    'south': -57 #3 \n",
    "  },\n",
    "\n",
    "    \n",
    "   # 'lead_low': \n",
    "   #   the number of months from the first of the initialization month to the center of \n",
    "   #   the first month included in the target period. Always an integer + 0.5. \n",
    "   #   this field is defined by a python floating point number \n",
    "   #   for example  a lead-1 forecast would use lead_low=1.5, if you want init=may, target=Jun-..\n",
    "  'lead_low': 1.5,\n",
    "    \n",
    "   # 'lead_high': \n",
    "   #   the number of months from the first of the initialization month to the center of \n",
    "   #   the last month included in the target period. Always an integer + 0.5. \n",
    "   #   this field is defined by a python floating point number \n",
    "   #   for example  a forecast initialized in may, whose target period ended in Aug, \n",
    "   #   would use lead_high=3.5\n",
    "  'lead_high': 3.5, \n",
    "    \n",
    "   # 'target': \n",
    "   #   Mmm-Mmm indicating the months included in the target period of the forecast. \n",
    "   #   this field is defined by a python string, with two three-letter month name abbreviations \n",
    "   #   whose first letters are capitalized, and all other letters are lowercase\n",
    "   #   and who are separated by a dash character. \n",
    "   #   for example, if you wanted a JJA target period, you would use 'Jun-Aug'\n",
    "  'target': 'Mar-May',#'Jul-Sep',\n",
    "    \n",
    "   # 'filetype':\n",
    "   #   the filetype to be downloaded. for now, it saves a lot of headache just to set this equal\n",
    "   #   to 'cptv10.tsv' which is a boutique plain-text CPT filetype based on .tsv + metadata\n",
    "  'filetype': 'cptv10.tsv'\n",
    "}\n",
    "\n",
    "cpt_args = { \n",
    "    'transform_predictand': None,  # transformation to apply to the predictand dataset - None, 'Empirical', 'Gamma'\n",
    "    'tailoring': None,  # tailoring None, 'Anomaly', 'StdAnomaly', or 'SPI' (SPI only available on Gamma)\n",
    "    'cca_modes': (1,3), # minimum and maximum of allowed CCA modes \n",
    "    'x_eof_modes': (1,8), # minimum and maximum of allowed X Principal Componenets \n",
    "    'y_eof_modes': (1,6), # minimum and maximum of allowed Y Principal Components \n",
    "    'validation': 'crossvalidation', # the type of validation to use - crossvalidation, retroactive, or doublecrossvalidation\n",
    "    'drymask': False, #whether or not to use a drymask of -999\n",
    "    'scree': True, # whether or not to save % explained variance for eof modes\n",
    "    'crossvalidation_window': 5,  # number of samples to leave out in each cross-validation step \n",
    "    'synchronous_predictors': True, # whether or not we are using 'synchronous predictors'\n",
    "}\n",
    "\n",
    "\n",
    "force_download = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288937d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "domain_dir = notebook.setup(case_dir, download_args[\"predictor_extent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95274754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following line & change the config filepath to save this configuration: \n",
    "config_file = ce.save_configuration(case_dir / 'config', download_args, cpt_args, MOS, predictor_names, predictand_name )\n",
    "print(\"Saved configuration to\", config_file)\n",
    "\n",
    "# Uncomment the following line & change the config filepath to load an existing configuration: \n",
    "#MOS, download_args, cpt_args, predictor_names, predictand_name = ce.load_configuration('test1.config')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bec2f65",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Visualize predictor and predictand domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa135f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "notebook.plot_domains(download_args['predictor_extent'], download_args['predictand_extent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656bb870",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Download Observations, Hindcasts, and Forecasts from IRI Data Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc64025",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "Y, hindcast_data, forecast_data = notebook.download_data(predictand_name, predictor_names, download_args, domain_dir, force_download)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa7f936",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Perform CPT Analysis\n",
    "Set `interactive = True` to see detailed output from CPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dc9c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfabb00",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hcsts, fcsts, skill, pxs, pys = notebook.evaluate_models(hindcast_data, MOS, Y, forecast_data, cpt_args, domain_dir, predictor_names, interactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a4b78",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Plot skill of individual models\n",
    "\n",
    "Deterministic skill metrics:\n",
    "- pearson\n",
    "- spearman\n",
    "- two_alternative_forced_choice\n",
    "- roc_area_below_normal (Area under ROC curve for Below Normal category)\n",
    "- roc_area_above_normal (Area under ROC curve for Above Normal category)\n",
    "\n",
    "Probabilistic skill metrics (in sample):\n",
    "- generalized_roc\n",
    "- rank_probability_skill_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547ab283",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "skill_metrics = [\n",
    "    \"pearson\",\n",
    "    \"spearman\",\n",
    "    \"two_alternative_forced_choice\",\n",
    "    \"roc_area_below_normal\",\n",
    "    \"roc_area_above_normal\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb38845",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "notebook.plot_skill(predictor_names, skill, MOS, domain_dir, skill_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd97f2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Plot EOF Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15041a5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notebook.plot_eof_modes(MOS, predictor_names, pxs, pys, domain_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d1e997",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Plot CCA Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815b054",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "notebook.plot_cca_modes(MOS, predictor_names, pxs, pys, domain_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee7ea4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Plot Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8240bd6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "notebook.plot_forecasts(cpt_args, predictand_name, fcsts, domain_dir, predictor_names, MOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ff6273",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Multi-Model Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ca5d1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Choose which models to include in the MME, e.g.\n",
    "```\n",
    "ensemble = ['CFSv2.PRCP','SEAS5.PRCP']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4636a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = predictor_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bf9e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "det_fcst, pr_fcst, pev_fcst, nextgen_skill = notebook.construct_mme(fcsts, hcsts, Y, ensemble, predictor_names, cpt_args, domain_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2904eba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Plot MME Forecast Skill\n",
    "\n",
    "Deterministic metrics: pearson, spearman, 2afc, roc_below, roc_above\n",
    "\n",
    "Probabilistic metrics: generalized_roc, rank_probability_skill_score \n",
    "\n",
    "e.g.\n",
    "```\n",
    "skill_metrics = [\"spearman\", \"generalized_roc\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c21848",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "skill_metrics = [\n",
    "    \"spearman\",\n",
    "    \"2afc\",\n",
    "    \"generalized_roc\",\n",
    "    \"rank_probability_skill_score\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2243b1b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "notebook.plot_mme_skill(predictor_names, nextgen_skill, MOS, domain_dir, skill_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d223d52d",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Plot MME Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c22a0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notebook.plot_mme_forecasts(cpt_args, predictand_name, pr_fcst, MOS, domain_dir, det_fcst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae1ace",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Construct MME Flexible Forecasts (full PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e588b245",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "If `isPercentile` is `True`, the threshold is a percentile (e.g., 0.5)\n",
    "else in the unit of the predictand (e.g., mm, degC, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40007cb0",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "isPercentile = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5d97c8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "exceedance_prob, fcst_scale, climo_scale, fcst_mu, climo_mu, Y2, ntrain, transformed_threshold = notebook.construct_flex_fcst(MOS, cpt_args, det_fcst, threshold, isPercentile, Y, pev_fcst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743fc138",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Plot Flexible MME Forecasts\n",
    "\n",
    "Choose a gridpoint within the predictand domain to plot the forecast and climatological probability of exceedance and PDF curves. If set to None, the centroid of the predictand domain will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149bc494",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "point_latitude = None\n",
    "point_longitude = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d235b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "notebook.plot_mme_flex_forecasts(predictand_name, exceedance_prob, point_latitude, point_longitude, download_args[\"predictand_extent\"], transformed_threshold, fcst_scale, climo_scale, fcst_mu, climo_mu, Y2, cpt_args['transform_predictand'], ntrain, Y, MOS, domain_dir)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
